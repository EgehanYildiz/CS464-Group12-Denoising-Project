2025-04-04 18:03:35,870 - INFO - Using device: cpu
2025-04-04 18:03:35,870 - INFO - Starting convolutional autoencoder training script
2025-04-04 18:03:35,870 - INFO - Configuration: batch_size=128, learning_rate=0.001, num_epochs=1
2025-04-04 18:03:35,870 - INFO - Loading data...
2025-04-04 18:03:43,672 - INFO - Loaded data shapes: Train: torch.Size([50000, 3, 32, 32]), Test: torch.Size([10000, 3, 32, 32])
2025-04-04 18:03:43,672 - INFO - Creating dataloaders...
2025-04-04 18:03:43,788 - INFO - Created dataloaders - Training: 45000 samples, Validation: 5000 samples, Test: 10000 samples
2025-04-04 18:03:43,789 - INFO - Initializing model...
2025-04-04 18:03:44,710 - INFO - Model architecture:
ConvAutoencoder(
  (encoder): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (decoder): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): ReLU(inplace=True)
    (2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
    (3): ReLU(inplace=True)
    (4): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))
    (5): Sigmoid()
  )
)
2025-04-04 18:03:44,710 - INFO - Starting model training...
2025-04-04 18:03:44,710 - INFO - Starting training for 1 epochs
2025-04-04 18:03:55,917 - INFO - Epoch [1/1], Batch [100/352], Loss: 0.020934
2025-04-04 18:04:11,582 - INFO - Epoch [1/1], Batch [200/352], Loss: 0.017599
2025-04-04 18:04:26,766 - INFO - Epoch [1/1], Batch [300/352], Loss: 0.013129
2025-04-04 18:04:36,986 - INFO - Epoch [1/1], Train Loss: 0.021417, Val Loss: 0.012386, Time: 52.28s
2025-04-04 18:04:36,991 - INFO - Saved best model at epoch 1 with validation loss: 0.012386
2025-04-04 18:04:37,245 - INFO - Loading best model for evaluation...
2025-04-04 18:04:37,249 - INFO - Evaluating model...
2025-04-04 18:04:52,872 - INFO - Evaluation results - MSE: 0.012322, PSNR: 19.59 dB, SSIM: 0.4214
2025-04-04 18:04:53,906 - INFO - Training and evaluation completed successfully!
2025-04-04 18:05:20,511 - INFO - Using device: cpu
2025-04-04 18:05:20,511 - INFO - Starting convolutional autoencoder training script
2025-04-04 18:05:20,511 - INFO - Configuration: batch_size=128, learning_rate=0.001, num_epochs=5
2025-04-04 18:05:20,511 - INFO - Loading data...
2025-04-04 18:05:28,015 - INFO - Loaded data shapes: Train: torch.Size([50000, 3, 32, 32]), Test: torch.Size([10000, 3, 32, 32])
2025-04-04 18:05:28,015 - INFO - Creating dataloaders...
2025-04-04 18:05:28,126 - INFO - Created dataloaders - Training: 45000 samples, Validation: 5000 samples, Test: 10000 samples
2025-04-04 18:05:28,126 - INFO - Initializing model...
2025-04-04 18:05:28,991 - INFO - Model architecture:
ConvAutoencoder(
  (encoder): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (decoder): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): ReLU(inplace=True)
    (2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
    (3): ReLU(inplace=True)
    (4): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))
    (5): Sigmoid()
  )
)
2025-04-04 18:05:28,991 - INFO - Starting model training...
2025-04-04 18:05:28,991 - INFO - Starting training for 5 epochs
2025-04-04 18:05:39,732 - INFO - Epoch [1/5], Batch [100/352], Loss: 0.022434
2025-04-04 18:05:54,413 - INFO - Epoch [1/5], Batch [200/352], Loss: 0.018429
2025-04-04 18:06:09,146 - INFO - Epoch [1/5], Batch [300/352], Loss: 0.015048
2025-04-04 18:06:19,322 - INFO - Epoch [1/5], Train Loss: 0.022157, Val Loss: 0.013596, Time: 50.33s
2025-04-04 18:06:19,325 - INFO - Saved best model at epoch 1 with validation loss: 0.013596
2025-04-04 18:06:34,312 - INFO - Epoch [2/5], Batch [100/352], Loss: 0.012996
2025-04-04 18:06:49,018 - INFO - Epoch [2/5], Batch [200/352], Loss: 0.011624
2025-04-04 18:07:03,745 - INFO - Epoch [2/5], Batch [300/352], Loss: 0.010870
2025-04-04 18:07:13,968 - INFO - Epoch [2/5], Train Loss: 0.011907, Val Loss: 0.010915, Time: 54.64s
2025-04-04 18:07:13,971 - INFO - Saved best model at epoch 2 with validation loss: 0.010915
2025-04-04 18:07:29,627 - INFO - Epoch [3/5], Batch [100/352], Loss: 0.009717
2025-04-04 18:07:44,678 - INFO - Epoch [3/5], Batch [200/352], Loss: 0.010568
2025-04-04 18:07:59,518 - INFO - Epoch [3/5], Batch [300/352], Loss: 0.010896
2025-04-04 18:08:09,745 - INFO - Epoch [3/5], Train Loss: 0.010366, Val Loss: 0.009706, Time: 55.77s
2025-04-04 18:08:09,748 - INFO - Saved best model at epoch 3 with validation loss: 0.009706
2025-04-04 18:08:24,630 - INFO - Epoch [4/5], Batch [100/352], Loss: 0.009468
2025-04-04 18:08:39,541 - INFO - Epoch [4/5], Batch [200/352], Loss: 0.008729
2025-04-04 18:08:54,862 - INFO - Epoch [4/5], Batch [300/352], Loss: 0.008838
2025-04-04 18:09:05,200 - INFO - Epoch [4/5], Train Loss: 0.009450, Val Loss: 0.008915, Time: 55.45s
2025-04-04 18:09:05,203 - INFO - Saved best model at epoch 4 with validation loss: 0.008915
2025-04-04 18:09:20,141 - INFO - Epoch [5/5], Batch [100/352], Loss: 0.008756
2025-04-04 18:09:35,014 - INFO - Epoch [5/5], Batch [200/352], Loss: 0.008885
2025-04-04 18:09:49,700 - INFO - Epoch [5/5], Batch [300/352], Loss: 0.008203
2025-04-04 18:09:59,933 - INFO - Epoch [5/5], Train Loss: 0.008643, Val Loss: 0.008209, Time: 54.73s
2025-04-04 18:09:59,936 - INFO - Saved best model at epoch 5 with validation loss: 0.008209
2025-04-04 18:10:00,204 - INFO - Loading best model for evaluation...
2025-04-04 18:10:00,207 - INFO - Evaluating model...
2025-04-04 18:10:14,671 - INFO - Evaluation results - MSE: 0.008218, PSNR: 21.34 dB, SSIM: 0.5185
2025-04-04 18:10:15,635 - INFO - Training and evaluation completed successfully!
2025-04-04 18:15:14,308 - INFO - Using device: cpu
2025-04-04 18:15:14,308 - INFO - Starting convolutional autoencoder training script
2025-04-04 18:15:14,308 - INFO - Configuration: batch_size=128, learning_rate=0.001, num_epochs=5
2025-04-04 18:15:14,308 - INFO - Loading data...
2025-04-04 18:15:21,831 - INFO - Loaded data shapes: Train: torch.Size([50000, 3, 32, 32]), Test: torch.Size([10000, 3, 32, 32])
2025-04-04 18:15:21,832 - INFO - Creating dataloaders...
2025-04-04 18:15:21,960 - INFO - Created dataloaders - Training: 45000 samples, Validation: 5000 samples, Test: 10000 samples
2025-04-04 18:15:21,960 - INFO - Initializing model...
2025-04-04 18:15:22,924 - INFO - Model architecture:
ConvAutoencoder(
  (encoder): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (decoder): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): ReLU(inplace=True)
    (2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
    (3): ReLU(inplace=True)
    (4): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))
    (5): Sigmoid()
  )
)
2025-04-04 18:15:22,924 - INFO - Starting model training...
2025-04-04 18:15:22,924 - INFO - Starting training for 5 epochs
2025-04-04 18:15:37,487 - INFO - Epoch [1/5], Batch [100/352], Loss: 0.020496
2025-04-04 18:15:52,203 - INFO - Epoch [1/5], Batch [200/352], Loss: 0.015368
2025-04-04 18:16:06,913 - INFO - Epoch [1/5], Batch [300/352], Loss: 0.012000
2025-04-04 18:16:17,141 - INFO - Epoch [1/5], Train Loss: 0.020809, Val Loss: 0.012415, Time: 54.22s
2025-04-04 18:16:17,145 - INFO - Saved best model at epoch 1 with validation loss: 0.012415
2025-04-04 18:16:32,285 - INFO - Epoch [2/5], Batch [100/352], Loss: 0.011028
2025-04-04 18:16:47,042 - INFO - Epoch [2/5], Batch [200/352], Loss: 0.010368
2025-04-04 18:17:01,847 - INFO - Epoch [2/5], Batch [300/352], Loss: 0.010416
2025-04-04 18:17:12,136 - INFO - Epoch [2/5], Train Loss: 0.010959, Val Loss: 0.010039, Time: 54.99s
2025-04-04 18:17:12,140 - INFO - Saved best model at epoch 2 with validation loss: 0.010039
2025-04-04 18:17:27,327 - INFO - Epoch [3/5], Batch [100/352], Loss: 0.008961
2025-04-04 18:17:42,188 - INFO - Epoch [3/5], Batch [200/352], Loss: 0.009111
2025-04-04 18:17:57,075 - INFO - Epoch [3/5], Batch [300/352], Loss: 0.009004
2025-04-04 18:18:07,407 - INFO - Epoch [3/5], Train Loss: 0.009418, Val Loss: 0.008796, Time: 55.27s
2025-04-04 18:18:07,409 - INFO - Saved best model at epoch 3 with validation loss: 0.008796
2025-04-04 18:18:23,956 - INFO - Epoch [4/5], Batch [100/352], Loss: 0.008385
2025-04-04 18:18:40,373 - INFO - Epoch [4/5], Batch [200/352], Loss: 0.008212
2025-04-04 18:18:55,273 - INFO - Epoch [4/5], Batch [300/352], Loss: 0.008120
2025-04-04 18:19:05,580 - INFO - Epoch [4/5], Train Loss: 0.008484, Val Loss: 0.008133, Time: 58.17s
2025-04-04 18:19:05,583 - INFO - Saved best model at epoch 4 with validation loss: 0.008133
2025-04-04 18:19:23,261 - INFO - Epoch [5/5], Batch [100/352], Loss: 0.008885
2025-04-04 18:19:38,259 - INFO - Epoch [5/5], Batch [200/352], Loss: 0.008343
2025-04-04 18:19:53,698 - INFO - Epoch [5/5], Batch [300/352], Loss: 0.008079
2025-04-04 18:20:06,283 - INFO - Epoch [5/5], Train Loss: 0.007946, Val Loss: 0.007709, Time: 60.70s
2025-04-04 18:20:06,287 - INFO - Saved best model at epoch 5 with validation loss: 0.007709
2025-04-04 18:20:06,554 - INFO - Loading best model for evaluation...
2025-04-04 18:20:06,557 - INFO - Evaluating model...
2025-04-04 18:20:21,997 - INFO - Evaluation results - MSE: 0.007696, PSNR: 21.63 dB, SSIM: 0.5329
2025-04-04 18:20:22,959 - INFO - Training and evaluation completed successfully!
2025-04-04 18:21:27,784 - INFO - Using device: cpu
2025-04-04 18:21:27,784 - INFO - Starting convolutional autoencoder training script
2025-04-04 18:21:27,784 - INFO - Configuration: batch_size=128, learning_rate=0.001, num_epochs=50
2025-04-04 18:21:27,784 - INFO - Loading data...
2025-04-04 18:21:35,387 - INFO - Loaded data shapes: Train: torch.Size([50000, 3, 32, 32]), Test: torch.Size([10000, 3, 32, 32])
2025-04-04 18:21:35,387 - INFO - Creating dataloaders...
2025-04-04 18:21:35,517 - INFO - Created dataloaders - Training: 45000 samples, Validation: 5000 samples, Test: 10000 samples
2025-04-04 18:21:35,518 - INFO - Initializing model...
2025-04-04 18:21:36,563 - INFO - Model architecture:
ConvAutoencoder(
  (encoder): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (decoder): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): ReLU(inplace=True)
    (2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
    (3): ReLU(inplace=True)
    (4): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))
    (5): Sigmoid()
  )
)
2025-04-04 18:21:36,563 - INFO - Starting model training...
2025-04-04 18:21:36,563 - INFO - Starting training for 50 epochs
2025-04-04 18:24:52,763 - INFO - Epoch [1/50], Batch [100/352], Loss: 0.020229
2025-04-04 18:25:07,722 - INFO - Epoch [1/50], Batch [200/352], Loss: 0.016878
2025-04-04 18:25:28,553 - INFO - Epoch [1/50], Batch [300/352], Loss: 0.012831
2025-04-04 18:32:47,657 - INFO - Epoch [1/50], Train Loss: 0.021148, Val Loss: 0.012567, Time: 671.09s
2025-04-04 18:32:47,663 - INFO - Saved best model at epoch 1 with validation loss: 0.012567
2025-04-04 18:43:55,536 - INFO - Epoch [2/50], Batch [100/352], Loss: 0.011277
2025-04-04 18:44:12,983 - INFO - Epoch [2/50], Batch [200/352], Loss: 0.011410
2025-04-04 18:44:29,022 - INFO - Epoch [2/50], Batch [300/352], Loss: 0.010980
2025-04-04 18:44:39,529 - INFO - Epoch [2/50], Train Loss: 0.010919, Val Loss: 0.010309, Time: 711.87s
2025-04-04 18:44:39,532 - INFO - Saved best model at epoch 2 with validation loss: 0.010309
2025-04-04 18:44:59,732 - INFO - Epoch [3/50], Batch [100/352], Loss: 0.009876
2025-04-04 18:45:16,744 - INFO - Epoch [3/50], Batch [200/352], Loss: 0.009764
2025-04-04 18:45:37,056 - INFO - Epoch [3/50], Batch [300/352], Loss: 0.009935
2025-04-04 18:45:48,804 - INFO - Epoch [3/50], Train Loss: 0.009615, Val Loss: 0.009395, Time: 69.27s
2025-04-04 18:45:48,807 - INFO - Saved best model at epoch 3 with validation loss: 0.009395
2025-04-04 18:46:07,988 - INFO - Epoch [4/50], Batch [100/352], Loss: 0.008539
2025-04-04 18:46:29,317 - INFO - Epoch [4/50], Batch [200/352], Loss: 0.008645
2025-04-04 18:46:48,861 - INFO - Epoch [4/50], Batch [300/352], Loss: 0.008876
2025-04-04 18:47:00,881 - INFO - Epoch [4/50], Train Loss: 0.008669, Val Loss: 0.008357, Time: 72.07s
2025-04-04 18:47:00,884 - INFO - Saved best model at epoch 4 with validation loss: 0.008357
2025-04-04 18:47:17,776 - INFO - Epoch [5/50], Batch [100/352], Loss: 0.007874
2025-04-04 18:47:36,135 - INFO - Epoch [5/50], Batch [200/352], Loss: 0.007969
2025-04-04 18:47:57,002 - INFO - Epoch [5/50], Batch [300/352], Loss: 0.007966
2025-04-04 18:48:10,487 - INFO - Epoch [5/50], Train Loss: 0.007991, Val Loss: 0.008010, Time: 69.60s
2025-04-04 18:48:10,490 - INFO - Saved best model at epoch 5 with validation loss: 0.008010
2025-04-04 18:48:31,209 - INFO - Epoch [6/50], Batch [100/352], Loss: 0.007998
2025-04-04 18:48:50,665 - INFO - Epoch [6/50], Batch [200/352], Loss: 0.007444
2025-04-04 18:49:11,415 - INFO - Epoch [6/50], Batch [300/352], Loss: 0.008078
2025-04-04 18:49:25,846 - INFO - Epoch [6/50], Train Loss: 0.007625, Val Loss: 0.007535, Time: 75.36s
2025-04-04 18:49:25,850 - INFO - Saved best model at epoch 6 with validation loss: 0.007535
2025-04-04 18:49:44,492 - INFO - Epoch [7/50], Batch [100/352], Loss: 0.006896
2025-04-04 18:50:04,900 - INFO - Epoch [7/50], Batch [200/352], Loss: 0.006904
2025-04-04 18:50:26,830 - INFO - Epoch [7/50], Batch [300/352], Loss: 0.007112
2025-04-04 18:50:39,868 - INFO - Epoch [7/50], Train Loss: 0.007351, Val Loss: 0.007337, Time: 74.02s
2025-04-04 18:50:39,872 - INFO - Saved best model at epoch 7 with validation loss: 0.007337
2025-04-04 18:50:57,104 - INFO - Epoch [8/50], Batch [100/352], Loss: 0.006875
2025-04-04 18:51:13,895 - INFO - Epoch [8/50], Batch [200/352], Loss: 0.006930
2025-04-04 18:51:31,529 - INFO - Epoch [8/50], Batch [300/352], Loss: 0.007292
2025-04-04 18:51:44,137 - INFO - Epoch [8/50], Train Loss: 0.007125, Val Loss: 0.007149, Time: 64.26s
2025-04-04 18:51:44,140 - INFO - Saved best model at epoch 8 with validation loss: 0.007149
2025-04-04 18:52:03,925 - INFO - Epoch [9/50], Batch [100/352], Loss: 0.007115
2025-04-04 18:52:20,883 - INFO - Epoch [9/50], Batch [200/352], Loss: 0.007082
2025-04-04 18:52:37,208 - INFO - Epoch [9/50], Batch [300/352], Loss: 0.007016
2025-04-04 18:52:48,489 - INFO - Epoch [9/50], Train Loss: 0.006938, Val Loss: 0.006973, Time: 64.35s
2025-04-04 18:52:48,492 - INFO - Saved best model at epoch 9 with validation loss: 0.006973
2025-04-04 18:53:10,928 - INFO - Epoch [10/50], Batch [100/352], Loss: 0.007201
2025-04-04 18:53:33,871 - INFO - Epoch [10/50], Batch [200/352], Loss: 0.007129
2025-04-04 18:53:56,347 - INFO - Epoch [10/50], Batch [300/352], Loss: 0.006617
2025-04-04 18:54:11,814 - INFO - Epoch [10/50], Train Loss: 0.006790, Val Loss: 0.006790, Time: 83.32s
2025-04-04 18:54:11,820 - INFO - Saved best model at epoch 10 with validation loss: 0.006790
2025-04-04 18:54:34,576 - INFO - Epoch [11/50], Batch [100/352], Loss: 0.006647
2025-04-04 18:54:52,716 - INFO - Epoch [11/50], Batch [200/352], Loss: 0.006789
2025-04-04 18:55:10,579 - INFO - Epoch [11/50], Batch [300/352], Loss: 0.006568
2025-04-04 18:55:24,111 - INFO - Epoch [11/50], Train Loss: 0.006632, Val Loss: 0.006630, Time: 72.29s
2025-04-04 18:55:24,115 - INFO - Saved best model at epoch 11 with validation loss: 0.006630
2025-04-04 18:55:40,782 - INFO - Epoch [12/50], Batch [100/352], Loss: 0.006343
2025-04-04 18:55:55,859 - INFO - Epoch [12/50], Batch [200/352], Loss: 0.006742
2025-04-04 18:56:12,853 - INFO - Epoch [12/50], Batch [300/352], Loss: 0.006693
2025-04-04 18:56:25,308 - INFO - Epoch [12/50], Train Loss: 0.006515, Val Loss: 0.006628, Time: 61.19s
2025-04-04 18:56:25,312 - INFO - Saved best model at epoch 12 with validation loss: 0.006628
2025-04-04 18:56:41,980 - INFO - Epoch [13/50], Batch [100/352], Loss: 0.006751
2025-04-04 18:56:58,190 - INFO - Epoch [13/50], Batch [200/352], Loss: 0.005910
2025-04-04 18:57:15,959 - INFO - Epoch [13/50], Batch [300/352], Loss: 0.007131
2025-04-04 18:57:29,031 - INFO - Epoch [13/50], Train Loss: 0.006406, Val Loss: 0.006427, Time: 63.72s
2025-04-04 18:57:29,034 - INFO - Saved best model at epoch 13 with validation loss: 0.006427
2025-04-04 18:57:46,331 - INFO - Epoch [14/50], Batch [100/352], Loss: 0.005887
2025-04-04 18:58:03,374 - INFO - Epoch [14/50], Batch [200/352], Loss: 0.005822
2025-04-04 18:58:20,007 - INFO - Epoch [14/50], Batch [300/352], Loss: 0.006465
2025-04-04 18:58:31,723 - INFO - Epoch [14/50], Train Loss: 0.006297, Val Loss: 0.006347, Time: 62.69s
2025-04-04 18:58:31,726 - INFO - Saved best model at epoch 14 with validation loss: 0.006347
2025-04-04 18:58:47,528 - INFO - Epoch [15/50], Batch [100/352], Loss: 0.006199
2025-04-04 18:59:04,423 - INFO - Epoch [15/50], Batch [200/352], Loss: 0.006903
2025-04-04 18:59:23,122 - INFO - Epoch [15/50], Batch [300/352], Loss: 0.006054
2025-04-04 18:59:36,324 - INFO - Epoch [15/50], Train Loss: 0.006214, Val Loss: 0.006272, Time: 64.60s
2025-04-04 18:59:36,327 - INFO - Saved best model at epoch 15 with validation loss: 0.006272
2025-04-04 18:59:53,779 - INFO - Epoch [16/50], Batch [100/352], Loss: 0.005974
2025-04-04 19:00:11,694 - INFO - Epoch [16/50], Batch [200/352], Loss: 0.006350
2025-04-04 19:00:29,536 - INFO - Epoch [16/50], Batch [300/352], Loss: 0.006204
2025-04-04 19:00:45,359 - INFO - Epoch [16/50], Train Loss: 0.006117, Val Loss: 0.006139, Time: 69.03s
2025-04-04 19:00:45,363 - INFO - Saved best model at epoch 16 with validation loss: 0.006139
2025-04-04 19:01:07,901 - INFO - Epoch [17/50], Batch [100/352], Loss: 0.006660
2025-04-04 19:01:31,073 - INFO - Epoch [17/50], Batch [200/352], Loss: 0.005635
2025-04-04 19:01:53,779 - INFO - Epoch [17/50], Batch [300/352], Loss: 0.006425
2025-04-04 19:02:05,202 - INFO - Epoch [17/50], Train Loss: 0.006031, Val Loss: 0.006091, Time: 79.84s
2025-04-04 19:02:05,206 - INFO - Saved best model at epoch 17 with validation loss: 0.006091
2025-04-04 19:02:24,013 - INFO - Epoch [18/50], Batch [100/352], Loss: 0.005793
2025-04-04 19:02:41,129 - INFO - Epoch [18/50], Batch [200/352], Loss: 0.005793
2025-04-04 19:02:59,730 - INFO - Epoch [18/50], Batch [300/352], Loss: 0.005516
2025-04-04 19:03:12,702 - INFO - Epoch [18/50], Train Loss: 0.005970, Val Loss: 0.006061, Time: 67.50s
2025-04-04 19:03:12,705 - INFO - Saved best model at epoch 18 with validation loss: 0.006061
2025-04-04 19:03:29,399 - INFO - Epoch [19/50], Batch [100/352], Loss: 0.005788
2025-04-04 19:03:45,794 - INFO - Epoch [19/50], Batch [200/352], Loss: 0.006104
2025-04-04 19:04:03,508 - INFO - Epoch [19/50], Batch [300/352], Loss: 0.006081
2025-04-04 19:04:16,519 - INFO - Epoch [19/50], Train Loss: 0.005886, Val Loss: 0.005950, Time: 63.81s
2025-04-04 19:04:16,523 - INFO - Saved best model at epoch 19 with validation loss: 0.005950
2025-04-04 19:04:33,474 - INFO - Epoch [20/50], Batch [100/352], Loss: 0.005802
2025-04-04 19:04:52,393 - INFO - Epoch [20/50], Batch [200/352], Loss: 0.005514
2025-04-04 19:05:11,033 - INFO - Epoch [20/50], Batch [300/352], Loss: 0.005739
2025-04-04 19:05:23,977 - INFO - Epoch [20/50], Train Loss: 0.005837, Val Loss: 0.005886, Time: 67.45s
2025-04-04 19:05:23,980 - INFO - Saved best model at epoch 20 with validation loss: 0.005886
2025-04-04 19:05:40,935 - INFO - Epoch [21/50], Batch [100/352], Loss: 0.006260
2025-04-04 19:05:57,299 - INFO - Epoch [21/50], Batch [200/352], Loss: 0.005571
2025-04-04 19:06:13,666 - INFO - Epoch [21/50], Batch [300/352], Loss: 0.005770
2025-04-04 19:06:24,557 - INFO - Epoch [21/50], Train Loss: 0.005786, Val Loss: 0.005784, Time: 60.58s
2025-04-04 19:06:24,560 - INFO - Saved best model at epoch 21 with validation loss: 0.005784
2025-04-04 19:06:42,780 - INFO - Epoch [22/50], Batch [100/352], Loss: 0.006233
2025-04-04 19:07:01,361 - INFO - Epoch [22/50], Batch [200/352], Loss: 0.005771
2025-04-04 19:07:20,351 - INFO - Epoch [22/50], Batch [300/352], Loss: 0.006082
2025-04-04 19:07:35,654 - INFO - Epoch [22/50], Train Loss: 0.005723, Val Loss: 0.005861, Time: 71.09s
2025-04-04 19:07:54,754 - INFO - Epoch [23/50], Batch [100/352], Loss: 0.005376
2025-04-04 19:08:11,842 - INFO - Epoch [23/50], Batch [200/352], Loss: 0.005297
2025-04-04 19:08:33,143 - INFO - Epoch [23/50], Batch [300/352], Loss: 0.005806
2025-04-04 19:08:45,640 - INFO - Epoch [23/50], Train Loss: 0.005687, Val Loss: 0.005873, Time: 69.99s
2025-04-04 19:09:03,528 - INFO - Epoch [24/50], Batch [100/352], Loss: 0.005649
2025-04-04 19:09:20,096 - INFO - Epoch [24/50], Batch [200/352], Loss: 0.005423
2025-04-04 19:09:37,490 - INFO - Epoch [24/50], Batch [300/352], Loss: 0.005244
2025-04-04 19:09:50,042 - INFO - Epoch [24/50], Train Loss: 0.005639, Val Loss: 0.005912, Time: 64.40s
2025-04-04 19:10:06,874 - INFO - Epoch [25/50], Batch [100/352], Loss: 0.005568
2025-04-04 19:10:23,975 - INFO - Epoch [25/50], Batch [200/352], Loss: 0.005401
2025-04-04 19:10:40,854 - INFO - Epoch [25/50], Batch [300/352], Loss: 0.005398
2025-04-04 19:10:52,215 - INFO - Epoch [25/50], Train Loss: 0.005594, Val Loss: 0.005658, Time: 62.17s
2025-04-04 19:10:52,219 - INFO - Saved best model at epoch 25 with validation loss: 0.005658
2025-04-04 19:11:09,847 - INFO - Epoch [26/50], Batch [100/352], Loss: 0.005844
2025-04-04 19:11:28,183 - INFO - Epoch [26/50], Batch [200/352], Loss: 0.005534
2025-04-04 19:11:46,080 - INFO - Epoch [26/50], Batch [300/352], Loss: 0.005427
2025-04-04 19:11:58,490 - INFO - Epoch [26/50], Train Loss: 0.005561, Val Loss: 0.005595, Time: 66.27s
2025-04-04 19:11:58,493 - INFO - Saved best model at epoch 26 with validation loss: 0.005595
2025-04-04 19:12:16,684 - INFO - Epoch [27/50], Batch [100/352], Loss: 0.005775
2025-04-04 19:12:34,697 - INFO - Epoch [27/50], Batch [200/352], Loss: 0.005788
2025-04-04 19:12:53,222 - INFO - Epoch [27/50], Batch [300/352], Loss: 0.005414
2025-04-04 19:13:05,707 - INFO - Epoch [27/50], Train Loss: 0.005529, Val Loss: 0.005647, Time: 67.21s
2025-04-04 19:13:23,679 - INFO - Epoch [28/50], Batch [100/352], Loss: 0.005529
2025-04-04 19:13:41,661 - INFO - Epoch [28/50], Batch [200/352], Loss: 0.005278
2025-04-04 19:14:00,238 - INFO - Epoch [28/50], Batch [300/352], Loss: 0.005368
2025-04-04 19:14:12,471 - INFO - Epoch [28/50], Train Loss: 0.005476, Val Loss: 0.005539, Time: 66.76s
2025-04-04 19:14:12,474 - INFO - Saved best model at epoch 28 with validation loss: 0.005539
2025-04-04 19:14:31,079 - INFO - Epoch [29/50], Batch [100/352], Loss: 0.005555
2025-04-04 19:14:49,868 - INFO - Epoch [29/50], Batch [200/352], Loss: 0.005278
2025-04-04 19:15:08,430 - INFO - Epoch [29/50], Batch [300/352], Loss: 0.005226
2025-04-04 19:15:20,972 - INFO - Epoch [29/50], Train Loss: 0.005448, Val Loss: 0.005767, Time: 68.50s
2025-04-04 19:15:39,411 - INFO - Epoch [30/50], Batch [100/352], Loss: 0.005466
2025-04-04 19:15:57,979 - INFO - Epoch [30/50], Batch [200/352], Loss: 0.005408
2025-04-04 19:16:16,215 - INFO - Epoch [30/50], Batch [300/352], Loss: 0.005151
2025-04-04 19:16:28,879 - INFO - Epoch [30/50], Train Loss: 0.005417, Val Loss: 0.005560, Time: 67.91s
2025-04-04 19:16:47,031 - INFO - Epoch [31/50], Batch [100/352], Loss: 0.005663
2025-04-04 19:17:05,312 - INFO - Epoch [31/50], Batch [200/352], Loss: 0.005385
2025-04-04 19:17:23,428 - INFO - Epoch [31/50], Batch [300/352], Loss: 0.005593
2025-04-04 19:17:36,383 - INFO - Epoch [31/50], Train Loss: 0.005383, Val Loss: 0.005540, Time: 67.50s
2025-04-04 19:17:55,268 - INFO - Epoch [32/50], Batch [100/352], Loss: 0.004950
2025-04-04 19:18:15,451 - INFO - Epoch [32/50], Batch [200/352], Loss: 0.005147
2025-04-04 19:18:36,714 - INFO - Epoch [32/50], Batch [300/352], Loss: 0.005429
2025-04-04 19:18:49,840 - INFO - Epoch [32/50], Train Loss: 0.005351, Val Loss: 0.005400, Time: 73.46s
2025-04-04 19:18:49,844 - INFO - Saved best model at epoch 32 with validation loss: 0.005400
2025-04-04 19:19:09,076 - INFO - Epoch [33/50], Batch [100/352], Loss: 0.005510
2025-04-04 19:19:28,700 - INFO - Epoch [33/50], Batch [200/352], Loss: 0.005541
2025-04-04 19:19:46,053 - INFO - Epoch [33/50], Batch [300/352], Loss: 0.005032
2025-04-04 19:19:57,806 - INFO - Epoch [33/50], Train Loss: 0.005328, Val Loss: 0.005411, Time: 67.96s
2025-04-04 19:20:14,974 - INFO - Epoch [34/50], Batch [100/352], Loss: 0.005084
2025-04-04 19:20:31,493 - INFO - Epoch [34/50], Batch [200/352], Loss: 0.005252
2025-04-04 19:20:47,796 - INFO - Epoch [34/50], Batch [300/352], Loss: 0.005133
2025-04-04 19:21:03,138 - INFO - Epoch [34/50], Train Loss: 0.005292, Val Loss: 0.005443, Time: 65.33s
2025-04-04 19:21:21,234 - INFO - Epoch [35/50], Batch [100/352], Loss: 0.005336
2025-04-04 19:21:41,024 - INFO - Epoch [35/50], Batch [200/352], Loss: 0.005353
2025-04-04 19:21:58,374 - INFO - Epoch [35/50], Batch [300/352], Loss: 0.005303
2025-04-04 19:22:10,532 - INFO - Epoch [35/50], Train Loss: 0.005267, Val Loss: 0.005333, Time: 67.39s
2025-04-04 19:22:10,537 - INFO - Saved best model at epoch 35 with validation loss: 0.005333
2025-04-04 19:22:28,488 - INFO - Epoch [36/50], Batch [100/352], Loss: 0.005027
2025-04-04 19:22:49,686 - INFO - Epoch [36/50], Batch [200/352], Loss: 0.005479
2025-04-04 19:23:07,448 - INFO - Epoch [36/50], Batch [300/352], Loss: 0.005289
2025-04-04 19:23:19,361 - INFO - Epoch [36/50], Train Loss: 0.005249, Val Loss: 0.005298, Time: 68.82s
2025-04-04 19:23:19,365 - INFO - Saved best model at epoch 36 with validation loss: 0.005298
2025-04-04 19:23:37,171 - INFO - Epoch [37/50], Batch [100/352], Loss: 0.005142
2025-04-04 19:23:54,479 - INFO - Epoch [37/50], Batch [200/352], Loss: 0.005209
2025-04-04 19:24:12,828 - INFO - Epoch [37/50], Batch [300/352], Loss: 0.005044
2025-04-04 19:24:24,631 - INFO - Epoch [37/50], Train Loss: 0.005218, Val Loss: 0.005288, Time: 65.27s
2025-04-04 19:24:24,634 - INFO - Saved best model at epoch 37 with validation loss: 0.005288
2025-04-04 19:24:41,827 - INFO - Epoch [38/50], Batch [100/352], Loss: 0.005586
2025-04-04 19:24:58,998 - INFO - Epoch [38/50], Batch [200/352], Loss: 0.005015
2025-04-04 19:25:17,126 - INFO - Epoch [38/50], Batch [300/352], Loss: 0.005068
2025-04-04 19:25:31,845 - INFO - Epoch [38/50], Train Loss: 0.005200, Val Loss: 0.005233, Time: 67.21s
2025-04-04 19:25:31,848 - INFO - Saved best model at epoch 38 with validation loss: 0.005233
2025-04-04 19:25:50,522 - INFO - Epoch [39/50], Batch [100/352], Loss: 0.005162
2025-04-04 19:26:08,165 - INFO - Epoch [39/50], Batch [200/352], Loss: 0.005150
2025-04-04 19:26:25,011 - INFO - Epoch [39/50], Batch [300/352], Loss: 0.005189
2025-04-04 19:26:36,957 - INFO - Epoch [39/50], Train Loss: 0.005177, Val Loss: 0.005187, Time: 65.11s
2025-04-04 19:26:36,961 - INFO - Saved best model at epoch 39 with validation loss: 0.005187
2025-04-04 19:26:54,341 - INFO - Epoch [40/50], Batch [100/352], Loss: 0.005223
2025-04-04 19:27:11,078 - INFO - Epoch [40/50], Batch [200/352], Loss: 0.005199
2025-04-04 19:27:28,475 - INFO - Epoch [40/50], Batch [300/352], Loss: 0.004977
2025-04-04 19:27:40,917 - INFO - Epoch [40/50], Train Loss: 0.005156, Val Loss: 0.005287, Time: 63.96s
2025-04-04 19:27:58,034 - INFO - Epoch [41/50], Batch [100/352], Loss: 0.005284
2025-04-04 19:28:15,195 - INFO - Epoch [41/50], Batch [200/352], Loss: 0.005651
2025-04-04 19:28:32,383 - INFO - Epoch [41/50], Batch [300/352], Loss: 0.005270
2025-04-04 19:28:43,814 - INFO - Epoch [41/50], Train Loss: 0.005125, Val Loss: 0.005249, Time: 62.90s
2025-04-04 19:29:01,063 - INFO - Epoch [42/50], Batch [100/352], Loss: 0.005115
2025-04-04 19:29:18,199 - INFO - Epoch [42/50], Batch [200/352], Loss: 0.004846
2025-04-04 19:29:35,973 - INFO - Epoch [42/50], Batch [300/352], Loss: 0.005468
2025-04-04 19:29:47,476 - INFO - Epoch [42/50], Train Loss: 0.005117, Val Loss: 0.005147, Time: 63.66s
2025-04-04 19:29:47,479 - INFO - Saved best model at epoch 42 with validation loss: 0.005147
2025-04-04 19:30:07,119 - INFO - Epoch [43/50], Batch [100/352], Loss: 0.005154
2025-04-04 19:30:27,667 - INFO - Epoch [43/50], Batch [200/352], Loss: 0.005000
2025-04-04 19:30:45,153 - INFO - Epoch [43/50], Batch [300/352], Loss: 0.004969
2025-04-04 19:30:57,064 - INFO - Epoch [43/50], Train Loss: 0.005096, Val Loss: 0.005321, Time: 69.59s
2025-04-04 19:31:15,082 - INFO - Epoch [44/50], Batch [100/352], Loss: 0.005158
2025-04-04 19:31:32,786 - INFO - Epoch [44/50], Batch [200/352], Loss: 0.005146
2025-04-04 19:31:48,205 - INFO - Epoch [44/50], Batch [300/352], Loss: 0.004983
2025-04-04 19:31:58,674 - INFO - Epoch [44/50], Train Loss: 0.005080, Val Loss: 0.005120, Time: 61.61s
2025-04-04 19:31:58,677 - INFO - Saved best model at epoch 44 with validation loss: 0.005120
2025-04-04 19:32:13,847 - INFO - Epoch [45/50], Batch [100/352], Loss: 0.004973
2025-04-04 19:32:28,796 - INFO - Epoch [45/50], Batch [200/352], Loss: 0.005518
2025-04-04 19:32:43,935 - INFO - Epoch [45/50], Batch [300/352], Loss: 0.005036
2025-04-04 19:32:54,349 - INFO - Epoch [45/50], Train Loss: 0.005055, Val Loss: 0.005190, Time: 55.67s
2025-04-04 19:33:09,265 - INFO - Epoch [46/50], Batch [100/352], Loss: 0.005184
2025-04-04 19:33:24,205 - INFO - Epoch [46/50], Batch [200/352], Loss: 0.004853
2025-04-04 19:33:39,412 - INFO - Epoch [46/50], Batch [300/352], Loss: 0.005041
2025-04-04 19:33:49,856 - INFO - Epoch [46/50], Train Loss: 0.005044, Val Loss: 0.005106, Time: 55.51s
2025-04-04 19:33:49,859 - INFO - Saved best model at epoch 46 with validation loss: 0.005106
2025-04-04 19:34:06,531 - INFO - Epoch [47/50], Batch [100/352], Loss: 0.005164
2025-04-04 19:34:21,829 - INFO - Epoch [47/50], Batch [200/352], Loss: 0.005040
2025-04-04 19:34:36,971 - INFO - Epoch [47/50], Batch [300/352], Loss: 0.004698
2025-04-04 19:34:47,509 - INFO - Epoch [47/50], Train Loss: 0.005020, Val Loss: 0.005106, Time: 57.65s
2025-04-04 19:34:47,512 - INFO - Saved best model at epoch 47 with validation loss: 0.005106
2025-04-04 19:35:02,675 - INFO - Epoch [48/50], Batch [100/352], Loss: 0.005000
2025-04-04 19:35:17,754 - INFO - Epoch [48/50], Batch [200/352], Loss: 0.004797
2025-04-04 19:35:32,877 - INFO - Epoch [48/50], Batch [300/352], Loss: 0.005067
2025-04-04 19:35:43,406 - INFO - Epoch [48/50], Train Loss: 0.005001, Val Loss: 0.005157, Time: 55.89s
2025-04-04 19:35:58,592 - INFO - Epoch [49/50], Batch [100/352], Loss: 0.004694
2025-04-04 19:36:13,880 - INFO - Epoch [49/50], Batch [200/352], Loss: 0.005015
2025-04-04 19:36:29,101 - INFO - Epoch [49/50], Batch [300/352], Loss: 0.005252
2025-04-04 19:36:41,230 - INFO - Epoch [49/50], Train Loss: 0.004996, Val Loss: 0.005104, Time: 57.82s
2025-04-04 19:36:41,233 - INFO - Saved best model at epoch 49 with validation loss: 0.005104
2025-04-04 19:36:56,802 - INFO - Epoch [50/50], Batch [100/352], Loss: 0.005291
2025-04-04 19:37:13,079 - INFO - Epoch [50/50], Batch [200/352], Loss: 0.004759
2025-04-04 19:37:30,317 - INFO - Epoch [50/50], Batch [300/352], Loss: 0.005228
2025-04-04 19:37:42,483 - INFO - Epoch [50/50], Train Loss: 0.004971, Val Loss: 0.005025, Time: 61.25s
2025-04-04 19:37:42,487 - INFO - Saved best model at epoch 50 with validation loss: 0.005025
2025-04-04 19:37:42,785 - INFO - Loading best model for evaluation...
2025-04-04 19:37:42,788 - INFO - Evaluating model...
2025-04-04 19:38:00,058 - INFO - Evaluation results - MSE: 0.004973, PSNR: 23.48 dB, SSIM: 0.6382
2025-04-04 19:38:01,052 - INFO - Training and evaluation completed successfully!
2025-05-10 19:36:55,160 - INFO - Using device: cpu
2025-05-10 19:36:55,160 - INFO - Starting convolutional autoencoder training script
2025-05-10 19:36:55,160 - INFO - Configuration: batch_size=128, learning_rate=0.001, num_epochs=50
2025-05-10 19:36:55,160 - INFO - Loading data...
2025-05-10 19:36:59,571 - INFO - Loaded data shapes: Train: torch.Size([50000, 3, 32, 32]), Test: torch.Size([10000, 3, 32, 32])
2025-05-10 19:36:59,571 - INFO - Creating dataloaders...
2025-05-10 19:36:59,661 - INFO - Created dataloaders - Training: 45000 samples, Validation: 5000 samples, Test: 10000 samples
2025-05-10 19:36:59,661 - INFO - Initializing model...
2025-05-10 19:37:04,299 - INFO - Model architecture:
ConvAutoencoder(
  (encoder): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (decoder): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): ReLU(inplace=True)
    (2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
    (3): ReLU(inplace=True)
    (4): ConvTranspose2d(32, 3, kernel_size=(2, 2), stride=(2, 2))
    (5): Sigmoid()
  )
)
2025-05-10 19:37:04,299 - INFO - Starting model training...
2025-05-10 19:37:04,299 - INFO - Starting training for 50 epochs
2025-05-10 19:37:13,417 - INFO - Epoch [1/50], Batch [100/352], Loss: 0.021124
2025-05-10 19:37:22,560 - INFO - Epoch [1/50], Batch [200/352], Loss: 0.015853
2025-05-10 19:37:32,081 - INFO - Epoch [1/50], Batch [300/352], Loss: 0.013196
2025-05-10 19:37:37,852 - INFO - Epoch [1/50], Train Loss: 0.020913, Val Loss: 0.012448, Time: 33.55s
2025-05-10 19:37:37,859 - INFO - Saved best model at epoch 1 with validation loss: 0.012448
2025-05-10 19:37:47,557 - INFO - Epoch [2/50], Batch [100/352], Loss: 0.011666
2025-05-10 19:37:56,267 - INFO - Epoch [2/50], Batch [200/352], Loss: 0.010938
2025-05-10 19:38:04,934 - INFO - Epoch [2/50], Batch [300/352], Loss: 0.010731
2025-05-10 19:38:10,399 - INFO - Epoch [2/50], Train Loss: 0.011387, Val Loss: 0.010475, Time: 32.54s
2025-05-10 19:38:10,401 - INFO - Saved best model at epoch 2 with validation loss: 0.010475
2025-05-10 19:38:19,017 - INFO - Epoch [3/50], Batch [100/352], Loss: 0.009782
2025-05-10 19:38:27,559 - INFO - Epoch [3/50], Batch [200/352], Loss: 0.010067
2025-05-10 19:38:36,160 - INFO - Epoch [3/50], Batch [300/352], Loss: 0.010118
2025-05-10 19:38:41,650 - INFO - Epoch [3/50], Train Loss: 0.009963, Val Loss: 0.009435, Time: 31.25s
2025-05-10 19:38:41,651 - INFO - Saved best model at epoch 3 with validation loss: 0.009435
2025-05-10 19:38:50,231 - INFO - Epoch [4/50], Batch [100/352], Loss: 0.009577
2025-05-10 19:38:58,852 - INFO - Epoch [4/50], Batch [200/352], Loss: 0.008795
2025-05-10 19:39:07,397 - INFO - Epoch [4/50], Batch [300/352], Loss: 0.008959
2025-05-10 19:39:12,920 - INFO - Epoch [4/50], Train Loss: 0.008876, Val Loss: 0.008455, Time: 31.27s
2025-05-10 19:39:12,921 - INFO - Saved best model at epoch 4 with validation loss: 0.008455
2025-05-10 19:39:21,508 - INFO - Epoch [5/50], Batch [100/352], Loss: 0.008229
2025-05-10 19:39:30,785 - INFO - Epoch [5/50], Batch [200/352], Loss: 0.007987
2025-05-10 19:39:39,445 - INFO - Epoch [5/50], Batch [300/352], Loss: 0.008258
2025-05-10 19:39:44,888 - INFO - Epoch [5/50], Train Loss: 0.008208, Val Loss: 0.007911, Time: 31.97s
2025-05-10 19:39:44,890 - INFO - Saved best model at epoch 5 with validation loss: 0.007911
2025-05-10 19:39:53,446 - INFO - Epoch [6/50], Batch [100/352], Loss: 0.007956
2025-05-10 19:40:02,040 - INFO - Epoch [6/50], Batch [200/352], Loss: 0.007284
2025-05-10 19:40:10,561 - INFO - Epoch [6/50], Batch [300/352], Loss: 0.007355
2025-05-10 19:40:16,005 - INFO - Epoch [6/50], Train Loss: 0.007813, Val Loss: 0.007640, Time: 31.12s
2025-05-10 19:40:16,006 - INFO - Saved best model at epoch 6 with validation loss: 0.007640
2025-05-10 19:40:24,540 - INFO - Epoch [7/50], Batch [100/352], Loss: 0.007881
2025-05-10 19:40:33,802 - INFO - Epoch [7/50], Batch [200/352], Loss: 0.007280
2025-05-10 19:40:42,680 - INFO - Epoch [7/50], Batch [300/352], Loss: 0.007557
2025-05-10 19:40:48,273 - INFO - Epoch [7/50], Train Loss: 0.007494, Val Loss: 0.007461, Time: 32.27s
2025-05-10 19:40:48,275 - INFO - Saved best model at epoch 7 with validation loss: 0.007461
2025-05-10 19:40:56,881 - INFO - Epoch [8/50], Batch [100/352], Loss: 0.007301
2025-05-10 19:41:05,443 - INFO - Epoch [8/50], Batch [200/352], Loss: 0.007170
2025-05-10 19:41:14,017 - INFO - Epoch [8/50], Batch [300/352], Loss: 0.007777
2025-05-10 19:41:19,527 - INFO - Epoch [8/50], Train Loss: 0.007266, Val Loss: 0.007192, Time: 31.25s
2025-05-10 19:41:19,528 - INFO - Saved best model at epoch 8 with validation loss: 0.007192
2025-05-10 19:41:28,139 - INFO - Epoch [9/50], Batch [100/352], Loss: 0.006866
2025-05-10 19:41:36,767 - INFO - Epoch [9/50], Batch [200/352], Loss: 0.007130
2025-05-10 19:41:45,396 - INFO - Epoch [9/50], Batch [300/352], Loss: 0.006940
2025-05-10 19:41:50,877 - INFO - Epoch [9/50], Train Loss: 0.007077, Val Loss: 0.007011, Time: 31.35s
2025-05-10 19:41:50,879 - INFO - Saved best model at epoch 9 with validation loss: 0.007011
2025-05-10 19:41:59,504 - INFO - Epoch [10/50], Batch [100/352], Loss: 0.006786
2025-05-10 19:42:08,102 - INFO - Epoch [10/50], Batch [200/352], Loss: 0.006724
2025-05-10 19:42:16,993 - INFO - Epoch [10/50], Batch [300/352], Loss: 0.007362
2025-05-10 19:42:22,433 - INFO - Epoch [10/50], Train Loss: 0.006889, Val Loss: 0.006879, Time: 31.55s
2025-05-10 19:42:22,434 - INFO - Saved best model at epoch 10 with validation loss: 0.006879
2025-05-10 19:42:31,008 - INFO - Epoch [11/50], Batch [100/352], Loss: 0.006795
2025-05-10 19:42:39,560 - INFO - Epoch [11/50], Batch [200/352], Loss: 0.006401
2025-05-10 19:42:48,116 - INFO - Epoch [11/50], Batch [300/352], Loss: 0.006454
2025-05-10 19:42:53,549 - INFO - Epoch [11/50], Train Loss: 0.006738, Val Loss: 0.006694, Time: 31.11s
2025-05-10 19:42:53,550 - INFO - Saved best model at epoch 11 with validation loss: 0.006694
2025-05-10 19:43:02,144 - INFO - Epoch [12/50], Batch [100/352], Loss: 0.006580
2025-05-10 19:43:10,688 - INFO - Epoch [12/50], Batch [200/352], Loss: 0.006886
2025-05-10 19:43:19,259 - INFO - Epoch [12/50], Batch [300/352], Loss: 0.006584
2025-05-10 19:43:24,702 - INFO - Epoch [12/50], Train Loss: 0.006631, Val Loss: 0.006520, Time: 31.15s
2025-05-10 19:43:24,704 - INFO - Saved best model at epoch 12 with validation loss: 0.006520
2025-05-10 19:43:33,282 - INFO - Epoch [13/50], Batch [100/352], Loss: 0.006144
2025-05-10 19:43:41,929 - INFO - Epoch [13/50], Batch [200/352], Loss: 0.006474
2025-05-10 19:43:50,474 - INFO - Epoch [13/50], Batch [300/352], Loss: 0.006268
2025-05-10 19:43:55,932 - INFO - Epoch [13/50], Train Loss: 0.006509, Val Loss: 0.006482, Time: 31.23s
2025-05-10 19:43:55,933 - INFO - Saved best model at epoch 13 with validation loss: 0.006482
2025-05-10 19:44:04,409 - INFO - Epoch [14/50], Batch [100/352], Loss: 0.006445
2025-05-10 19:44:13,223 - INFO - Epoch [14/50], Batch [200/352], Loss: 0.006568
2025-05-10 19:44:22,167 - INFO - Epoch [14/50], Batch [300/352], Loss: 0.006131
2025-05-10 19:44:28,032 - INFO - Epoch [14/50], Train Loss: 0.006391, Val Loss: 0.006421, Time: 32.10s
2025-05-10 19:44:28,033 - INFO - Saved best model at epoch 14 with validation loss: 0.006421
2025-05-10 19:44:37,155 - INFO - Epoch [15/50], Batch [100/352], Loss: 0.006252
2025-05-10 19:44:46,252 - INFO - Epoch [15/50], Batch [200/352], Loss: 0.006476
2025-05-10 19:44:55,317 - INFO - Epoch [15/50], Batch [300/352], Loss: 0.006281
2025-05-10 19:45:01,206 - INFO - Epoch [15/50], Train Loss: 0.006307, Val Loss: 0.006524, Time: 33.17s
2025-05-10 19:45:10,286 - INFO - Epoch [16/50], Batch [100/352], Loss: 0.006478
2025-05-10 19:45:19,317 - INFO - Epoch [16/50], Batch [200/352], Loss: 0.006164
2025-05-10 19:45:29,037 - INFO - Epoch [16/50], Batch [300/352], Loss: 0.006225
2025-05-10 19:45:35,606 - INFO - Epoch [16/50], Train Loss: 0.006208, Val Loss: 0.006253, Time: 34.40s
2025-05-10 19:45:35,608 - INFO - Saved best model at epoch 16 with validation loss: 0.006253
2025-05-10 19:45:45,862 - INFO - Epoch [17/50], Batch [100/352], Loss: 0.006460
2025-05-10 19:45:55,940 - INFO - Epoch [17/50], Batch [200/352], Loss: 0.006175
2025-05-10 19:46:05,611 - INFO - Epoch [17/50], Batch [300/352], Loss: 0.006213
2025-05-10 19:46:11,976 - INFO - Epoch [17/50], Train Loss: 0.006131, Val Loss: 0.006125, Time: 36.37s
2025-05-10 19:46:11,977 - INFO - Saved best model at epoch 17 with validation loss: 0.006125
2025-05-10 19:46:21,717 - INFO - Epoch [18/50], Batch [100/352], Loss: 0.006079
2025-05-10 19:46:31,742 - INFO - Epoch [18/50], Batch [200/352], Loss: 0.006424
2025-05-10 19:46:42,011 - INFO - Epoch [18/50], Batch [300/352], Loss: 0.005925
2025-05-10 19:46:48,601 - INFO - Epoch [18/50], Train Loss: 0.006048, Val Loss: 0.006036, Time: 36.62s
2025-05-10 19:46:48,604 - INFO - Saved best model at epoch 18 with validation loss: 0.006036
2025-05-10 19:46:58,497 - INFO - Epoch [19/50], Batch [100/352], Loss: 0.005891
2025-05-10 19:47:08,865 - INFO - Epoch [19/50], Batch [200/352], Loss: 0.006100
2025-05-10 19:47:18,510 - INFO - Epoch [19/50], Batch [300/352], Loss: 0.006682
2025-05-10 19:47:24,873 - INFO - Epoch [19/50], Train Loss: 0.005984, Val Loss: 0.006116, Time: 36.27s
2025-05-10 19:47:34,873 - INFO - Epoch [20/50], Batch [100/352], Loss: 0.005962
2025-05-10 19:47:44,433 - INFO - Epoch [20/50], Batch [200/352], Loss: 0.006333
2025-05-10 19:47:53,522 - INFO - Epoch [20/50], Batch [300/352], Loss: 0.006251
2025-05-10 19:47:59,450 - INFO - Epoch [20/50], Train Loss: 0.005922, Val Loss: 0.005843, Time: 34.58s
2025-05-10 19:47:59,451 - INFO - Saved best model at epoch 20 with validation loss: 0.005843
2025-05-10 19:48:08,568 - INFO - Epoch [21/50], Batch [100/352], Loss: 0.006014
2025-05-10 19:48:17,576 - INFO - Epoch [21/50], Batch [200/352], Loss: 0.005786
2025-05-10 19:48:26,558 - INFO - Epoch [21/50], Batch [300/352], Loss: 0.006072
2025-05-10 19:48:32,406 - INFO - Epoch [21/50], Train Loss: 0.005859, Val Loss: 0.005930, Time: 32.95s
2025-05-10 19:48:41,513 - INFO - Epoch [22/50], Batch [100/352], Loss: 0.005575
2025-05-10 19:48:50,551 - INFO - Epoch [22/50], Batch [200/352], Loss: 0.005582
2025-05-10 19:48:59,561 - INFO - Epoch [22/50], Batch [300/352], Loss: 0.006086
2025-05-10 19:49:05,371 - INFO - Epoch [22/50], Train Loss: 0.005817, Val Loss: 0.005773, Time: 32.96s
2025-05-10 19:49:05,373 - INFO - Saved best model at epoch 22 with validation loss: 0.005773
2025-05-10 19:49:14,590 - INFO - Epoch [23/50], Batch [100/352], Loss: 0.005429
2025-05-10 19:49:24,154 - INFO - Epoch [23/50], Batch [200/352], Loss: 0.005527
2025-05-10 19:49:33,191 - INFO - Epoch [23/50], Batch [300/352], Loss: 0.005499
2025-05-10 19:49:39,168 - INFO - Epoch [23/50], Train Loss: 0.005763, Val Loss: 0.005777, Time: 33.79s
2025-05-10 19:49:48,262 - INFO - Epoch [24/50], Batch [100/352], Loss: 0.005454
2025-05-10 19:49:57,310 - INFO - Epoch [24/50], Batch [200/352], Loss: 0.005469
2025-05-10 19:50:06,328 - INFO - Epoch [24/50], Batch [300/352], Loss: 0.005739
2025-05-10 19:50:12,208 - INFO - Epoch [24/50], Train Loss: 0.005718, Val Loss: 0.005814, Time: 33.04s
2025-05-10 19:50:21,287 - INFO - Epoch [25/50], Batch [100/352], Loss: 0.005906
2025-05-10 19:50:30,337 - INFO - Epoch [25/50], Batch [200/352], Loss: 0.005737
2025-05-10 19:50:39,410 - INFO - Epoch [25/50], Batch [300/352], Loss: 0.005676
2025-05-10 19:50:45,302 - INFO - Epoch [25/50], Train Loss: 0.005669, Val Loss: 0.005714, Time: 33.09s
2025-05-10 19:50:45,304 - INFO - Saved best model at epoch 25 with validation loss: 0.005714
2025-05-10 19:50:54,386 - INFO - Epoch [26/50], Batch [100/352], Loss: 0.005616
2025-05-10 19:51:03,408 - INFO - Epoch [26/50], Batch [200/352], Loss: 0.005436
2025-05-10 19:51:12,477 - INFO - Epoch [26/50], Batch [300/352], Loss: 0.005436
2025-05-10 19:51:18,354 - INFO - Epoch [26/50], Train Loss: 0.005630, Val Loss: 0.005610, Time: 33.05s
2025-05-10 19:51:18,356 - INFO - Saved best model at epoch 26 with validation loss: 0.005610
2025-05-10 19:51:27,464 - INFO - Epoch [27/50], Batch [100/352], Loss: 0.005477
2025-05-10 19:51:36,530 - INFO - Epoch [27/50], Batch [200/352], Loss: 0.005444
2025-05-10 19:51:45,644 - INFO - Epoch [27/50], Batch [300/352], Loss: 0.005607
2025-05-10 19:51:51,567 - INFO - Epoch [27/50], Train Loss: 0.005591, Val Loss: 0.005628, Time: 33.21s
2025-05-10 19:52:00,707 - INFO - Epoch [28/50], Batch [100/352], Loss: 0.005520
2025-05-10 19:52:09,760 - INFO - Epoch [28/50], Batch [200/352], Loss: 0.005448
2025-05-10 19:52:18,842 - INFO - Epoch [28/50], Batch [300/352], Loss: 0.005866
2025-05-10 19:52:24,730 - INFO - Epoch [28/50], Train Loss: 0.005551, Val Loss: 0.005552, Time: 33.16s
2025-05-10 19:52:24,732 - INFO - Saved best model at epoch 28 with validation loss: 0.005552
2025-05-10 19:52:34,093 - INFO - Epoch [29/50], Batch [100/352], Loss: 0.005589
2025-05-10 19:53:09,528 - INFO - Epoch [29/50], Batch [200/352], Loss: 0.005294
2025-05-10 19:53:18,268 - INFO - Epoch [29/50], Batch [300/352], Loss: 0.005626
2025-05-10 19:53:23,724 - INFO - Epoch [29/50], Train Loss: 0.005519, Val Loss: 0.005570, Time: 58.99s
2025-05-10 19:53:32,301 - INFO - Epoch [30/50], Batch [100/352], Loss: 0.005726
2025-05-10 19:53:40,858 - INFO - Epoch [30/50], Batch [200/352], Loss: 0.005310
2025-05-10 19:53:49,420 - INFO - Epoch [30/50], Batch [300/352], Loss: 0.005797
2025-05-10 19:53:54,895 - INFO - Epoch [30/50], Train Loss: 0.005480, Val Loss: 0.005572, Time: 31.17s
2025-05-10 19:54:03,560 - INFO - Epoch [31/50], Batch [100/352], Loss: 0.005401
2025-05-10 19:54:12,239 - INFO - Epoch [31/50], Batch [200/352], Loss: 0.005180
2025-05-10 19:54:20,798 - INFO - Epoch [31/50], Batch [300/352], Loss: 0.005713
2025-05-10 19:54:26,264 - INFO - Epoch [31/50], Train Loss: 0.005467, Val Loss: 0.005531, Time: 31.37s
2025-05-10 19:54:26,266 - INFO - Saved best model at epoch 31 with validation loss: 0.005531
2025-05-10 19:54:34,852 - INFO - Epoch [32/50], Batch [100/352], Loss: 0.005050
2025-05-10 19:54:43,434 - INFO - Epoch [32/50], Batch [200/352], Loss: 0.005510
2025-05-10 19:54:51,938 - INFO - Epoch [32/50], Batch [300/352], Loss: 0.005182
2025-05-10 19:54:57,526 - INFO - Epoch [32/50], Train Loss: 0.005411, Val Loss: 0.005569, Time: 31.26s
2025-05-10 19:55:06,316 - INFO - Epoch [33/50], Batch [100/352], Loss: 0.005443
2025-05-10 19:55:15,323 - INFO - Epoch [33/50], Batch [200/352], Loss: 0.005450
2025-05-10 19:55:24,566 - INFO - Epoch [33/50], Batch [300/352], Loss: 0.005533
2025-05-10 19:55:30,648 - INFO - Epoch [33/50], Train Loss: 0.005394, Val Loss: 0.005431, Time: 33.12s
2025-05-10 19:55:30,649 - INFO - Saved best model at epoch 33 with validation loss: 0.005431
2025-05-10 19:55:40,155 - INFO - Epoch [34/50], Batch [100/352], Loss: 0.005253
2025-05-10 19:55:49,752 - INFO - Epoch [34/50], Batch [200/352], Loss: 0.005202
2025-05-10 19:55:59,410 - INFO - Epoch [34/50], Batch [300/352], Loss: 0.005366
2025-05-10 19:56:05,717 - INFO - Epoch [34/50], Train Loss: 0.005363, Val Loss: 0.005460, Time: 35.07s
2025-05-10 19:56:15,985 - INFO - Epoch [35/50], Batch [100/352], Loss: 0.005145
2025-05-10 19:56:25,752 - INFO - Epoch [35/50], Batch [200/352], Loss: 0.005223
2025-05-10 19:56:35,479 - INFO - Epoch [35/50], Batch [300/352], Loss: 0.005408
2025-05-10 19:56:41,761 - INFO - Epoch [35/50], Train Loss: 0.005339, Val Loss: 0.005325, Time: 36.04s
2025-05-10 19:56:41,763 - INFO - Saved best model at epoch 35 with validation loss: 0.005325
2025-05-10 19:56:51,410 - INFO - Epoch [36/50], Batch [100/352], Loss: 0.005226
2025-05-10 19:57:00,935 - INFO - Epoch [36/50], Batch [200/352], Loss: 0.005633
2025-05-10 19:57:10,413 - INFO - Epoch [36/50], Batch [300/352], Loss: 0.005307
2025-05-10 19:57:16,566 - INFO - Epoch [36/50], Train Loss: 0.005305, Val Loss: 0.005310, Time: 34.80s
2025-05-10 19:57:16,567 - INFO - Saved best model at epoch 36 with validation loss: 0.005310
2025-05-10 19:57:26,098 - INFO - Epoch [37/50], Batch [100/352], Loss: 0.005427
2025-05-10 19:57:35,448 - INFO - Epoch [37/50], Batch [200/352], Loss: 0.005572
2025-05-10 19:57:44,784 - INFO - Epoch [37/50], Batch [300/352], Loss: 0.005243
2025-05-10 19:57:50,822 - INFO - Epoch [37/50], Train Loss: 0.005284, Val Loss: 0.005338, Time: 34.25s
2025-05-10 19:58:00,212 - INFO - Epoch [38/50], Batch [100/352], Loss: 0.005611
2025-05-10 19:58:09,538 - INFO - Epoch [38/50], Batch [200/352], Loss: 0.005292
2025-05-10 19:58:18,847 - INFO - Epoch [38/50], Batch [300/352], Loss: 0.004870
2025-05-10 19:58:24,913 - INFO - Epoch [38/50], Train Loss: 0.005266, Val Loss: 0.005276, Time: 34.09s
2025-05-10 19:58:24,915 - INFO - Saved best model at epoch 38 with validation loss: 0.005276
2025-05-10 19:58:34,244 - INFO - Epoch [39/50], Batch [100/352], Loss: 0.004992
2025-05-10 19:58:43,495 - INFO - Epoch [39/50], Batch [200/352], Loss: 0.005082
2025-05-10 19:58:52,733 - INFO - Epoch [39/50], Batch [300/352], Loss: 0.005103
2025-05-10 19:58:58,773 - INFO - Epoch [39/50], Train Loss: 0.005228, Val Loss: 0.005275, Time: 33.86s
2025-05-10 19:58:58,774 - INFO - Saved best model at epoch 39 with validation loss: 0.005275
2025-05-10 19:59:08,206 - INFO - Epoch [40/50], Batch [100/352], Loss: 0.005019
2025-05-10 19:59:18,352 - INFO - Epoch [40/50], Batch [200/352], Loss: 0.004984
2025-05-10 19:59:28,773 - INFO - Epoch [40/50], Batch [300/352], Loss: 0.005356
2025-05-10 19:59:38,855 - INFO - Epoch [40/50], Train Loss: 0.005218, Val Loss: 0.005358, Time: 40.08s
2025-05-10 19:59:52,409 - INFO - Epoch [41/50], Batch [100/352], Loss: 0.005238
2025-05-10 20:00:03,918 - INFO - Epoch [41/50], Batch [200/352], Loss: 0.005252
2025-05-10 20:00:14,973 - INFO - Epoch [41/50], Batch [300/352], Loss: 0.005212
2025-05-10 20:00:22,170 - INFO - Epoch [41/50], Train Loss: 0.005197, Val Loss: 0.005275, Time: 43.31s
2025-05-10 20:00:32,972 - INFO - Epoch [42/50], Batch [100/352], Loss: 0.005233
2025-05-10 20:00:42,737 - INFO - Epoch [42/50], Batch [200/352], Loss: 0.005063
2025-05-10 20:00:52,435 - INFO - Epoch [42/50], Batch [300/352], Loss: 0.005148
2025-05-10 20:00:59,272 - INFO - Epoch [42/50], Train Loss: 0.005177, Val Loss: 0.005223, Time: 37.10s
2025-05-10 20:00:59,274 - INFO - Saved best model at epoch 42 with validation loss: 0.005223
2025-05-10 20:01:08,992 - INFO - Epoch [43/50], Batch [100/352], Loss: 0.005774
2025-05-10 20:01:18,501 - INFO - Epoch [43/50], Batch [200/352], Loss: 0.004984
2025-05-10 20:01:27,967 - INFO - Epoch [43/50], Batch [300/352], Loss: 0.004846
2025-05-10 20:01:34,079 - INFO - Epoch [43/50], Train Loss: 0.005145, Val Loss: 0.005133, Time: 34.81s
2025-05-10 20:01:34,081 - INFO - Saved best model at epoch 43 with validation loss: 0.005133
2025-05-10 20:01:43,540 - INFO - Epoch [44/50], Batch [100/352], Loss: 0.005074
2025-05-10 20:01:52,890 - INFO - Epoch [44/50], Batch [200/352], Loss: 0.005115
2025-05-10 20:02:02,353 - INFO - Epoch [44/50], Batch [300/352], Loss: 0.004895
2025-05-10 20:02:08,414 - INFO - Epoch [44/50], Train Loss: 0.005141, Val Loss: 0.005216, Time: 34.33s
2025-05-10 20:02:17,805 - INFO - Epoch [45/50], Batch [100/352], Loss: 0.005079
2025-05-10 20:02:27,128 - INFO - Epoch [45/50], Batch [200/352], Loss: 0.005265
2025-05-10 20:02:36,391 - INFO - Epoch [45/50], Batch [300/352], Loss: 0.005115
2025-05-10 20:02:42,407 - INFO - Epoch [45/50], Train Loss: 0.005110, Val Loss: 0.005162, Time: 33.99s
2025-05-10 20:02:51,719 - INFO - Epoch [46/50], Batch [100/352], Loss: 0.005191
2025-05-10 20:03:01,019 - INFO - Epoch [46/50], Batch [200/352], Loss: 0.005110
2025-05-10 20:03:10,300 - INFO - Epoch [46/50], Batch [300/352], Loss: 0.004857
2025-05-10 20:03:16,691 - INFO - Epoch [46/50], Train Loss: 0.005110, Val Loss: 0.005101, Time: 34.28s
2025-05-10 20:03:16,692 - INFO - Saved best model at epoch 46 with validation loss: 0.005101
2025-05-10 20:03:26,955 - INFO - Epoch [47/50], Batch [100/352], Loss: 0.005292
2025-05-10 20:03:36,432 - INFO - Epoch [47/50], Batch [200/352], Loss: 0.004800
2025-05-10 20:03:45,877 - INFO - Epoch [47/50], Batch [300/352], Loss: 0.005447
2025-05-10 20:03:52,001 - INFO - Epoch [47/50], Train Loss: 0.005077, Val Loss: 0.005178, Time: 35.31s
2025-05-10 20:04:01,519 - INFO - Epoch [48/50], Batch [100/352], Loss: 0.005145
2025-05-10 20:04:10,990 - INFO - Epoch [48/50], Batch [200/352], Loss: 0.005330
2025-05-10 20:04:20,428 - INFO - Epoch [48/50], Batch [300/352], Loss: 0.004826
2025-05-10 20:04:26,592 - INFO - Epoch [48/50], Train Loss: 0.005071, Val Loss: 0.005110, Time: 34.59s
2025-05-10 20:04:36,047 - INFO - Epoch [49/50], Batch [100/352], Loss: 0.005096
2025-05-10 20:04:45,572 - INFO - Epoch [49/50], Batch [200/352], Loss: 0.005158
2025-05-10 20:04:54,964 - INFO - Epoch [49/50], Batch [300/352], Loss: 0.005121
2025-05-10 20:05:01,057 - INFO - Epoch [49/50], Train Loss: 0.005043, Val Loss: 0.005106, Time: 34.46s
2025-05-10 20:05:10,508 - INFO - Epoch [50/50], Batch [100/352], Loss: 0.005023
2025-05-10 20:05:19,901 - INFO - Epoch [50/50], Batch [200/352], Loss: 0.004691
2025-05-10 20:05:29,295 - INFO - Epoch [50/50], Batch [300/352], Loss: 0.005143
2025-05-10 20:05:35,399 - INFO - Epoch [50/50], Train Loss: 0.005038, Val Loss: 0.005181, Time: 34.34s
2025-05-10 20:05:36,407 - INFO - Loading best model for evaluation...
2025-05-10 20:05:36,411 - INFO - Evaluating model...
2025-05-10 20:05:43,850 - INFO - Evaluation results - MSE: 0.005067, PSNR: 23.41 dB, SSIM: 0.6335
2025-05-10 20:05:44,537 - INFO - Training and evaluation completed successfully!
2025-05-10 22:07:27,990 - INFO - Using device: cpu
2025-05-10 22:07:27,990 - INFO - Starting convolutional autoencoder training script
2025-05-10 22:07:27,990 - INFO - Configuration: batch_size=128, learning_rate=0.001, num_epochs=50
2025-05-10 22:07:27,990 - INFO - Loading data...
2025-05-10 22:07:35,669 - INFO - Loaded data shapes: Train: torch.Size([50000, 3, 32, 32]), Test: torch.Size([10000, 3, 32, 32])
2025-05-10 22:07:35,669 - INFO - Creating dataloaders...
2025-05-10 22:07:35,794 - INFO - Created dataloaders - Training: 45000 samples, Validation: 5000 samples, Test: 10000 samples
2025-05-10 22:07:35,794 - INFO - Initializing model...
2025-05-10 22:07:37,048 - INFO - Model architecture:
ConvAutoencoder(
  (encoder): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): LeakyReLU(negative_slope=0.2, inplace=True)
    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (decoder): Sequential(
    (0): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
    (9): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): LeakyReLU(negative_slope=0.2, inplace=True)
    (12): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): LeakyReLU(negative_slope=0.2, inplace=True)
    (15): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (16): Sigmoid()
  )
)
2025-05-10 22:07:37,048 - INFO - Starting model training...
2025-05-10 22:07:37,049 - INFO - Starting training for 50 epochs
2025-05-10 22:08:27,328 - INFO - Epoch [1/50], Batch [100/352], Loss: 0.007853
2025-05-10 22:09:17,475 - INFO - Epoch [1/50], Batch [200/352], Loss: 0.006784
2025-05-10 22:10:07,838 - INFO - Epoch [1/50], Batch [300/352], Loss: 0.004685
2025-05-10 22:10:38,436 - INFO - Epoch [1/50], Train Loss: 0.008026, Val Loss: 0.004901, Time: 181.39s
2025-05-10 22:10:38,446 - INFO - Saved best model at epoch 1 with validation loss: 0.004901
2025-05-10 22:13:57,793 - INFO - Epoch [2/50], Batch [100/352], Loss: 0.004183
2025-05-10 22:14:41,387 - INFO - Epoch [2/50], Batch [200/352], Loss: 0.004900
2025-05-10 22:15:16,466 - INFO - Epoch [2/50], Batch [300/352], Loss: 0.003452
2025-05-10 22:15:37,751 - INFO - Epoch [2/50], Train Loss: 0.004013, Val Loss: 0.003975, Time: 299.30s
2025-05-10 22:15:37,754 - INFO - Saved best model at epoch 2 with validation loss: 0.003975
2025-05-10 22:16:12,465 - INFO - Epoch [3/50], Batch [100/352], Loss: 0.004270
2025-05-10 22:16:47,122 - INFO - Epoch [3/50], Batch [200/352], Loss: 0.003243
2025-05-10 22:17:21,840 - INFO - Epoch [3/50], Batch [300/352], Loss: 0.003244
2025-05-10 22:17:43,366 - INFO - Epoch [3/50], Train Loss: 0.003535, Val Loss: 0.003691, Time: 125.61s
2025-05-10 22:17:43,369 - INFO - Saved best model at epoch 3 with validation loss: 0.003691
2025-05-10 22:28:28,398 - INFO - Epoch [4/50], Batch [100/352], Loss: 0.003181
2025-05-10 22:30:13,335 - INFO - Using device: cpu
2025-05-10 22:30:13,335 - INFO - Starting convolutional autoencoder training script
2025-05-10 22:30:13,335 - INFO - Configuration: batch_size=256, learning_rate=0.001, num_epochs=30
2025-05-10 22:30:13,335 - INFO - Loading data...
2025-05-10 22:30:17,767 - INFO - Loaded data shapes: Train: torch.Size([50000, 3, 32, 32]), Test: torch.Size([10000, 3, 32, 32])
2025-05-10 22:30:17,767 - INFO - Creating dataloaders...
2025-05-10 22:30:17,848 - INFO - Created dataloaders - Training: 45000 samples, Validation: 5000 samples, Test: 10000 samples
2025-05-10 22:30:17,849 - INFO - Initializing model...
2025-05-10 22:30:18,595 - ERROR - An error occurred: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'
2025-05-10 22:30:33,893 - INFO - Using device: cpu
2025-05-10 22:30:33,893 - INFO - Starting convolutional autoencoder training script
2025-05-10 22:30:33,893 - INFO - Configuration: batch_size=256, learning_rate=0.001, num_epochs=30
2025-05-10 22:30:33,893 - INFO - Loading data...
2025-05-10 22:30:38,103 - INFO - Loaded data shapes: Train: torch.Size([50000, 3, 32, 32]), Test: torch.Size([10000, 3, 32, 32])
2025-05-10 22:30:38,103 - INFO - Creating dataloaders...
2025-05-10 22:30:38,184 - INFO - Created dataloaders - Training: 45000 samples, Validation: 5000 samples, Test: 10000 samples
2025-05-10 22:30:38,184 - INFO - Initializing model...
2025-05-10 22:30:38,735 - ERROR - An error occurred: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'
2025-05-10 22:31:06,603 - INFO - Using device: cpu
2025-05-10 22:31:06,603 - INFO - Starting convolutional autoencoder training script
2025-05-10 22:31:06,603 - INFO - Configuration: batch_size=256, learning_rate=0.001, num_epochs=30
2025-05-10 22:31:06,603 - INFO - Loading data...
2025-05-10 22:31:10,728 - INFO - Loaded data shapes: Train: torch.Size([50000, 3, 32, 32]), Test: torch.Size([10000, 3, 32, 32])
2025-05-10 22:31:10,728 - INFO - Creating dataloaders...
2025-05-10 22:31:10,813 - INFO - Created dataloaders - Training: 45000 samples, Validation: 5000 samples, Test: 10000 samples
2025-05-10 22:31:10,813 - INFO - Initializing model...
2025-05-10 22:31:11,361 - INFO - Model architecture:
ConvAutoencoder(
  (encoder): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (decoder): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (7): Sigmoid()
  )
)
2025-05-10 22:31:11,361 - INFO - Starting model training...
2025-05-10 22:31:11,361 - INFO - Starting training for 30 epochs
2025-05-10 22:31:40,748 - INFO - Epoch [1/30], Train Loss: 0.011340, Val Loss: 0.005191, Time: 29.39s
2025-05-10 22:31:40,753 - INFO - Saved best model at epoch 1 with validation loss: 0.005191
2025-05-10 22:32:08,787 - INFO - Epoch [2/30], Train Loss: 0.004510, Val Loss: 0.003876, Time: 28.03s
2025-05-10 22:32:08,790 - INFO - Saved best model at epoch 2 with validation loss: 0.003876
2025-05-10 22:32:36,161 - INFO - Epoch [3/30], Train Loss: 0.003560, Val Loss: 0.003308, Time: 27.37s
2025-05-10 22:32:36,163 - INFO - Saved best model at epoch 3 with validation loss: 0.003308
2025-05-10 22:33:03,481 - INFO - Epoch [4/30], Train Loss: 0.003177, Val Loss: 0.002974, Time: 27.32s
2025-05-10 22:33:03,483 - INFO - Saved best model at epoch 4 with validation loss: 0.002974
2025-05-10 22:33:31,273 - INFO - Epoch [5/30], Train Loss: 0.002953, Val Loss: 0.002987, Time: 27.79s
2025-05-10 22:33:58,808 - INFO - Epoch [6/30], Train Loss: 0.002793, Val Loss: 0.002724, Time: 27.53s
2025-05-10 22:33:58,810 - INFO - Saved best model at epoch 6 with validation loss: 0.002724
2025-05-10 22:34:26,440 - INFO - Epoch [7/30], Train Loss: 0.002700, Val Loss: 0.002954, Time: 27.63s
2025-05-10 22:34:53,918 - INFO - Epoch [8/30], Train Loss: 0.002594, Val Loss: 0.002596, Time: 27.48s
2025-05-10 22:34:53,920 - INFO - Saved best model at epoch 8 with validation loss: 0.002596
2025-05-10 22:35:21,450 - INFO - Epoch [9/30], Train Loss: 0.002537, Val Loss: 0.002443, Time: 27.53s
2025-05-10 22:35:21,452 - INFO - Saved best model at epoch 9 with validation loss: 0.002443
2025-05-10 22:35:49,270 - INFO - Epoch [10/30], Train Loss: 0.002476, Val Loss: 0.002405, Time: 27.82s
2025-05-10 22:35:49,272 - INFO - Saved best model at epoch 10 with validation loss: 0.002405
2025-05-10 22:36:16,713 - INFO - Epoch [11/30], Train Loss: 0.002391, Val Loss: 0.002307, Time: 27.44s
2025-05-10 22:36:16,716 - INFO - Saved best model at epoch 11 with validation loss: 0.002307
2025-05-10 22:36:44,396 - INFO - Epoch [12/30], Train Loss: 0.002364, Val Loss: 0.002350, Time: 27.68s
2025-05-10 22:37:11,933 - INFO - Epoch [13/30], Train Loss: 0.002344, Val Loss: 0.002258, Time: 27.54s
2025-05-10 22:37:11,935 - INFO - Saved best model at epoch 13 with validation loss: 0.002258
2025-05-10 22:37:39,494 - INFO - Epoch [14/30], Train Loss: 0.002291, Val Loss: 0.002237, Time: 27.56s
2025-05-10 22:37:39,496 - INFO - Saved best model at epoch 14 with validation loss: 0.002237
2025-05-10 22:38:06,946 - INFO - Epoch [15/30], Train Loss: 0.002260, Val Loss: 0.002176, Time: 27.45s
2025-05-10 22:38:06,948 - INFO - Saved best model at epoch 15 with validation loss: 0.002176
2025-05-10 22:38:34,395 - INFO - Epoch [16/30], Train Loss: 0.002232, Val Loss: 0.002248, Time: 27.45s
2025-05-10 22:39:02,473 - INFO - Epoch [17/30], Train Loss: 0.002219, Val Loss: 0.002132, Time: 28.08s
2025-05-10 22:39:02,475 - INFO - Saved best model at epoch 17 with validation loss: 0.002132
2025-05-10 22:39:30,099 - INFO - Epoch [18/30], Train Loss: 0.002186, Val Loss: 0.002089, Time: 27.62s
2025-05-10 22:39:30,102 - INFO - Saved best model at epoch 18 with validation loss: 0.002089
2025-05-10 22:39:57,852 - INFO - Epoch [19/30], Train Loss: 0.002170, Val Loss: 0.002092, Time: 27.75s
2025-05-10 22:40:25,565 - INFO - Epoch [20/30], Train Loss: 0.002125, Val Loss: 0.002264, Time: 27.71s
2025-05-10 22:40:53,279 - INFO - Epoch [21/30], Train Loss: 0.002116, Val Loss: 0.002197, Time: 27.71s
2025-05-10 22:41:21,032 - INFO - Epoch [22/30], Train Loss: 0.002093, Val Loss: 0.002091, Time: 27.75s
2025-05-10 22:41:48,685 - INFO - Epoch [23/30], Train Loss: 0.002093, Val Loss: 0.001978, Time: 27.65s
2025-05-10 22:41:48,687 - INFO - Saved best model at epoch 23 with validation loss: 0.001978
2025-05-10 22:42:16,412 - INFO - Epoch [24/30], Train Loss: 0.002071, Val Loss: 0.001991, Time: 27.72s
2025-05-10 22:44:49,322 - INFO - Epoch [25/30], Train Loss: 0.002047, Val Loss: 0.002119, Time: 152.91s
2025-05-10 22:45:16,945 - INFO - Epoch [26/30], Train Loss: 0.002057, Val Loss: 0.002008, Time: 27.62s
2025-05-10 22:45:44,463 - INFO - Epoch [27/30], Train Loss: 0.002059, Val Loss: 0.002013, Time: 27.52s
2025-05-10 22:46:11,929 - INFO - Epoch [28/30], Train Loss: 0.002019, Val Loss: 0.001946, Time: 27.47s
2025-05-10 22:46:11,931 - INFO - Saved best model at epoch 28 with validation loss: 0.001946
2025-05-10 22:46:39,835 - INFO - Epoch [29/30], Train Loss: 0.002019, Val Loss: 0.002008, Time: 27.90s
2025-05-11 00:57:56,993 - INFO - Using device: cpu
2025-05-11 00:57:56,993 - INFO - Starting convolutional autoencoder training script
2025-05-11 00:57:56,993 - INFO - Configuration: batch_size=256, learning_rate=0.001, num_epochs=50
2025-05-11 00:57:56,993 - INFO - Loading data...
2025-05-11 00:58:05,004 - INFO - Loaded data shapes: Train: torch.Size([50000, 3, 32, 32]), Test: torch.Size([10000, 3, 32, 32])
2025-05-11 00:58:05,005 - INFO - Creating dataloaders...
2025-05-11 00:58:05,140 - INFO - Created dataloaders - Training: 45000 samples, Validation: 5000 samples, Test: 10000 samples
2025-05-11 00:58:05,140 - INFO - Initializing model...
2025-05-11 00:58:07,129 - INFO - Model architecture:
ConvAutoencoder(
  (encoder): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (decoder): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2, inplace=True)
    (6): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (7): Sigmoid()
  )
)
2025-05-11 00:58:07,129 - INFO - Starting model training...
2025-05-11 00:58:07,129 - INFO - Starting training for 50 epochs
2025-05-11 00:58:45,467 - INFO - Epoch [1/50], Train Loss: 0.011985, Val Loss: 0.005307, Time: 38.34s
2025-05-11 00:58:45,478 - INFO - Saved best model at epoch 1 with validation loss: 0.005307
2025-05-11 00:59:23,116 - INFO - Epoch [2/50], Train Loss: 0.004424, Val Loss: 0.003904, Time: 37.64s
2025-05-11 00:59:23,121 - INFO - Saved best model at epoch 2 with validation loss: 0.003904
2025-05-11 01:00:01,413 - INFO - Epoch [3/50], Train Loss: 0.003513, Val Loss: 0.003261, Time: 38.29s
2025-05-11 01:00:01,419 - INFO - Saved best model at epoch 3 with validation loss: 0.003261
2025-05-11 01:00:40,056 - INFO - Epoch [4/50], Train Loss: 0.003144, Val Loss: 0.002913, Time: 38.64s
2025-05-11 01:00:40,061 - INFO - Saved best model at epoch 4 with validation loss: 0.002913
2025-05-11 01:01:18,542 - INFO - Epoch [5/50], Train Loss: 0.002938, Val Loss: 0.002841, Time: 38.48s
2025-05-11 01:01:18,548 - INFO - Saved best model at epoch 5 with validation loss: 0.002841
2025-05-11 01:01:56,836 - INFO - Epoch [6/50], Train Loss: 0.002826, Val Loss: 0.002680, Time: 38.29s
2025-05-11 01:01:56,840 - INFO - Saved best model at epoch 6 with validation loss: 0.002680
2025-05-11 01:02:34,994 - INFO - Epoch [7/50], Train Loss: 0.002701, Val Loss: 0.002588, Time: 38.15s
2025-05-11 01:02:34,998 - INFO - Saved best model at epoch 7 with validation loss: 0.002588
2025-05-11 01:03:13,312 - INFO - Epoch [8/50], Train Loss: 0.002582, Val Loss: 0.002584, Time: 38.31s
2025-05-11 01:03:13,316 - INFO - Saved best model at epoch 8 with validation loss: 0.002584
2025-05-11 01:03:51,821 - INFO - Epoch [9/50], Train Loss: 0.002524, Val Loss: 0.002531, Time: 38.51s
2025-05-11 01:03:51,825 - INFO - Saved best model at epoch 9 with validation loss: 0.002531
2025-05-11 01:04:31,006 - INFO - Epoch [10/50], Train Loss: 0.002466, Val Loss: 0.002945, Time: 39.18s
2025-05-11 01:05:09,359 - INFO - Epoch [11/50], Train Loss: 0.002402, Val Loss: 0.002319, Time: 38.35s
2025-05-11 01:05:09,364 - INFO - Saved best model at epoch 11 with validation loss: 0.002319
2025-05-11 01:05:48,155 - INFO - Epoch [12/50], Train Loss: 0.002342, Val Loss: 0.002322, Time: 38.79s
2025-05-11 01:06:26,529 - INFO - Epoch [13/50], Train Loss: 0.002311, Val Loss: 0.002194, Time: 38.37s
2025-05-11 01:06:26,534 - INFO - Saved best model at epoch 13 with validation loss: 0.002194
2025-05-11 01:07:04,599 - INFO - Epoch [14/50], Train Loss: 0.002297, Val Loss: 0.002187, Time: 38.06s
2025-05-11 01:07:04,603 - INFO - Saved best model at epoch 14 with validation loss: 0.002187
2025-05-11 01:07:43,275 - INFO - Epoch [15/50], Train Loss: 0.002269, Val Loss: 0.002172, Time: 38.67s
2025-05-11 01:07:43,280 - INFO - Saved best model at epoch 15 with validation loss: 0.002172
2025-05-11 01:08:21,772 - INFO - Epoch [16/50], Train Loss: 0.002239, Val Loss: 0.002144, Time: 38.49s
2025-05-11 01:08:21,775 - INFO - Saved best model at epoch 16 with validation loss: 0.002144
2025-05-11 01:09:00,546 - INFO - Epoch [17/50], Train Loss: 0.002189, Val Loss: 0.002105, Time: 38.77s
2025-05-11 01:09:00,552 - INFO - Saved best model at epoch 17 with validation loss: 0.002105
2025-05-11 01:09:38,666 - INFO - Epoch [18/50], Train Loss: 0.002161, Val Loss: 0.002173, Time: 38.11s
2025-05-11 01:10:16,988 - INFO - Epoch [19/50], Train Loss: 0.002141, Val Loss: 0.002045, Time: 38.32s
2025-05-11 01:10:16,993 - INFO - Saved best model at epoch 19 with validation loss: 0.002045
2025-05-11 01:11:04,880 - INFO - Epoch [20/50], Train Loss: 0.002152, Val Loss: 0.002260, Time: 47.89s
2025-05-11 01:11:43,395 - INFO - Epoch [21/50], Train Loss: 0.002149, Val Loss: 0.002023, Time: 38.51s
2025-05-11 01:11:43,401 - INFO - Saved best model at epoch 21 with validation loss: 0.002023
2025-05-11 01:12:23,947 - INFO - Epoch [22/50], Train Loss: 0.002126, Val Loss: 0.002252, Time: 40.55s
2025-05-11 01:13:02,714 - INFO - Epoch [23/50], Train Loss: 0.002098, Val Loss: 0.002088, Time: 38.77s
2025-05-11 01:14:59,736 - INFO - Epoch [24/50], Train Loss: 0.002079, Val Loss: 0.001996, Time: 117.02s
2025-05-11 01:14:59,742 - INFO - Saved best model at epoch 24 with validation loss: 0.001996
2025-05-11 01:15:41,596 - INFO - Epoch [25/50], Train Loss: 0.002057, Val Loss: 0.002055, Time: 41.85s
2025-05-11 01:16:12,693 - INFO - Epoch [26/50], Train Loss: 0.002046, Val Loss: 0.001959, Time: 31.10s
2025-05-11 01:16:12,697 - INFO - Saved best model at epoch 26 with validation loss: 0.001959
2025-05-11 01:16:41,798 - INFO - Epoch [27/50], Train Loss: 0.002041, Val Loss: 0.001984, Time: 29.10s
2025-05-11 01:17:10,879 - INFO - Epoch [28/50], Train Loss: 0.002013, Val Loss: 0.001971, Time: 29.08s
2025-05-11 01:17:40,422 - INFO - Epoch [29/50], Train Loss: 0.002009, Val Loss: 0.002015, Time: 29.54s
2025-05-11 01:18:12,368 - INFO - Epoch [30/50], Train Loss: 0.002019, Val Loss: 0.001927, Time: 31.95s
2025-05-11 01:18:12,370 - INFO - Saved best model at epoch 30 with validation loss: 0.001927
2025-05-11 01:18:42,328 - INFO - Epoch [31/50], Train Loss: 0.001981, Val Loss: 0.001915, Time: 29.96s
2025-05-11 01:18:42,330 - INFO - Saved best model at epoch 31 with validation loss: 0.001915
2025-05-11 01:19:11,994 - INFO - Epoch [32/50], Train Loss: 0.002003, Val Loss: 0.002488, Time: 29.66s
2025-05-11 01:19:41,067 - INFO - Epoch [33/50], Train Loss: 0.002005, Val Loss: 0.002145, Time: 29.07s
2025-05-11 01:20:12,252 - INFO - Epoch [34/50], Train Loss: 0.001988, Val Loss: 0.002037, Time: 31.18s
2025-05-11 01:20:41,590 - INFO - Epoch [35/50], Train Loss: 0.001980, Val Loss: 0.001974, Time: 29.34s
2025-05-11 01:21:09,811 - INFO - Epoch [36/50], Train Loss: 0.001961, Val Loss: 0.002122, Time: 28.22s
2025-05-11 01:21:37,663 - INFO - Epoch [37/50], Train Loss: 0.001951, Val Loss: 0.001976, Time: 27.85s
2025-05-11 01:22:05,718 - INFO - Epoch [38/50], Train Loss: 0.001899, Val Loss: 0.001829, Time: 28.06s
2025-05-11 01:22:05,723 - INFO - Saved best model at epoch 38 with validation loss: 0.001829
2025-05-11 01:22:34,050 - INFO - Epoch [39/50], Train Loss: 0.001914, Val Loss: 0.001945, Time: 28.33s
2025-05-11 01:23:02,251 - INFO - Epoch [40/50], Train Loss: 0.001904, Val Loss: 0.001869, Time: 28.20s
2025-05-11 01:23:30,699 - INFO - Epoch [41/50], Train Loss: 0.001907, Val Loss: 0.001935, Time: 28.45s
2025-05-11 01:24:01,449 - INFO - Epoch [42/50], Train Loss: 0.001908, Val Loss: 0.001829, Time: 30.75s
2025-05-11 01:25:00,627 - INFO - Epoch [43/50], Train Loss: 0.001893, Val Loss: 0.001865, Time: 59.18s
2025-05-11 01:37:08,459 - INFO - Epoch [44/50], Train Loss: 0.001899, Val Loss: 0.001883, Time: 727.83s
2025-05-11 01:37:37,835 - INFO - Epoch [45/50], Train Loss: 0.001859, Val Loss: 0.001829, Time: 29.38s
2025-05-11 01:38:09,620 - INFO - Epoch [46/50], Train Loss: 0.001860, Val Loss: 0.001796, Time: 31.78s
2025-05-11 01:38:09,622 - INFO - Saved best model at epoch 46 with validation loss: 0.001796
2025-05-11 01:38:40,499 - INFO - Epoch [47/50], Train Loss: 0.001860, Val Loss: 0.001785, Time: 30.88s
2025-05-11 01:38:40,501 - INFO - Saved best model at epoch 47 with validation loss: 0.001785
2025-05-11 01:39:10,447 - INFO - Epoch [48/50], Train Loss: 0.001864, Val Loss: 0.001789, Time: 29.95s
2025-05-11 01:39:41,388 - INFO - Epoch [49/50], Train Loss: 0.001859, Val Loss: 0.001818, Time: 30.94s
2025-05-11 01:40:12,120 - INFO - Epoch [50/50], Train Loss: 0.001853, Val Loss: 0.001801, Time: 30.73s
2025-05-11 01:40:12,534 - INFO - Loading best model for evaluation...
2025-05-11 01:40:12,539 - INFO - Evaluating model...
2025-05-11 01:40:19,319 - INFO - Evaluation results - MSE: 0.001790, PSNR: 27.69 dB, SSIM: 0.8181
2025-05-11 01:40:19,910 - INFO - Training and evaluation completed successfully!
